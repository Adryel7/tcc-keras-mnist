{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOfPfASmswd7"
   },
   "source": [
    "# Título do Trabalho: Keras: Democratizando o Acesso ao Aprendizado Profundo\n",
    "---\n",
    "**Instituição:** Centro Universitário Carioca – UniCarioca\n",
    "**Curso:** Engenharia da Computação  \n",
    "**Disciplina:** Trabalho de Conclusão de Curso  \n",
    "**Semestre:** 2025/2  \n",
    "**Versão do Código:** 1.0 (Stable Release)  \n",
    "\n",
    "**Equipe de Desenvolvimento:**\n",
    "* **Adryel Salles Leite de Almeida** (Matrícula: 2020100122) – adryel7@gmail.com\n",
    "* **Felipe S. de Lima** (Matrícula: 2021100794) – lima.felipesalles@gmail.com\n",
    "* **Lucas C. Junker** (Matrícula: 2020102270) – lcsjunker@gmail.com\n",
    "\n",
    "**Orientador(a):** Professor Ricardo Pires Mesquita   \n",
    "\n",
    "---\n",
    "### Objetivo\n",
    "\n",
    "Demonstrar a viabilidade técnica e a simplicidade de implementação de Redes Neurais Artificiais (RNAs) utilizando o *framework* Keras, comprovando como ferramentas de alto nível democratizam o acesso ao Aprendizado Profundo (*Deep Learning*) para resolução de problemas de classificação de padrões.\n",
    "\n",
    "---\n",
    "### Metodologia\n",
    "\n",
    "A presente pesquisa classifica-se como aplicada e quantitativa, adotando uma abordagem experimental para o desenvolvimento e validação do modelo de aprendizado de máquina. O procedimento metodológico foi estruturado em quatro etapas sequenciais:\n",
    "\n",
    "**1. Ambiente de Desenvolvimento e Ferramentas:** O projeto foi desenvolvido na linguagem Python, utilizando o ambiente de execução em nuvem Google Colab, que fornece recursos computacionais necessários para o treinamento de redes neurais. As principais bibliotecas utilizadas foram:\n",
    "\n",
    "**TensorFlow/Keras:** Para construção, compilação e treinamento da rede neural.\n",
    "\n",
    "**Pandas e NumPy:** Para manipulação algébrica de dados e estruturação de logs.\n",
    "\n",
    "**Matplotlib e Seaborn:** Para visualização de dados e geração de gráficos de desempenho.\n",
    "\n",
    "**Scikit-learn:** Para cálculo de métricas avançadas de avaliação.\n",
    "\n",
    "**2. Preparação e Pré-processamento dos Dados:** Utilizou-se o *dataset* MNIST (70.000 imagens de dígitos manuscritos). O *pipeline* de dados incluiu:\n",
    "\n",
    "**Normalização:** Conversão dos valores de pixel da escala [0, 255] para [0, 1] para acelerar a convergência do gradiente.\n",
    "\n",
    "**Definição de Sementes (*Seeds*):** Fixação de sementes aleatórias (seed=42) para garantir a reprodutibilidade científica dos experimentos.\n",
    "\n",
    "***Data Augmentation*:** Aplicação de transformações dinâmicas (rotação, zoom e translação) durante o treinamento para aumentar a robustez do modelo contra variações espaciais.\n",
    "\n",
    "**3. Arquitetura e Treinamento:** Foi definida uma arquitetura do tipo *Feedforward* (MLP) sequencial, composta por:\n",
    "\n",
    "Camada de entrada (*Flatten*) para vetorização da imagem 28x28.\n",
    "\n",
    "Camada oculta densa com 128 neurônios e função de ativação ReLU.\n",
    "\n",
    "Camada de saída com 10 neurônios e função de ativação Softmax (distribuição de probabilidades). O treinamento utilizou o otimizador Adam e a função de perda *Sparse Categorical Crossentropy* ao longo de 15 épocas.\n",
    "\n",
    "**4. Avaliação e Validação Prática:** A análise de resultados não se limitou à acurácia global. Foram gerados gráficos de histórico de treinamento para monitorar a convergência e uma Matriz de Confusão para identificar classes ambíguas. Por fim, realizou-se um Teste Prático de Inferência, submetendo o modelo a imagens externas desenhadas digitalmente, pré-processadas (inversão de cores e redimensionamento) para validar a eficácia da solução em ambiente de produção.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bw9mA99ajJzF"
   },
   "source": [
    "Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sP4wiFtS52PQ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYXgnEZAjNz5"
   },
   "source": [
    "Reprodutibilidade e Definições de pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xFN5u1S428Y"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "PROJECT_VERSION = \"1.0\"\n",
    "\n",
    "BASE_OUTPUTS = 'outputs'\n",
    "BASE_MODELS = 'models'\n",
    "BASE_DATA = os.path.join('data')\n",
    "\n",
    "os.makedirs(BASE_OUTPUTS, exist_ok=True)\n",
    "os.makedirs(BASE_MODELS, exist_ok=True)\n",
    "os.makedirs(BASE_DATA, exist_ok=True)\n",
    "\n",
    "print(f\"--- Sistema Iniciado - Versão {PROJECT_VERSION} ---\")\n",
    "print(\"Ambiente configurado e sementes definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB4TXLdHYSgz"
   },
   "source": [
    "**Etapa 1 - Preparação dos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGVKeJM16rW5"
   },
   "source": [
    "Carregamento e preparação do *dataset* MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6hqykH55uNY"
   },
   "outputs": [],
   "source": [
    "mnist=keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "826yUzXk7Ru4"
   },
   "source": [
    "Normalização dos pixels para o intervalo [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVsV386d7XKK"
   },
   "outputs": [],
   "source": [
    "train_images, test_images = train_images/255.0, test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XahXjPYN6mFq"
   },
   "source": [
    "*Reshape* para 4 dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IJQ8qIu6x05"
   },
   "outputs": [],
   "source": [
    "train_images_aug = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images_aug = test_images.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8ungGBP-uvM"
   },
   "source": [
    "**Etapa 2 - Definição da arquitetura**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWMT1dD0-63e"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoS1Drn3_YC1"
   },
   "source": [
    "**Etapa 3 - Compilação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFIfloE-_AGR"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKckGnpQ_yDt"
   },
   "source": [
    "**Etapa 4 - Treinamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K8CyWWMtSWi"
   },
   "source": [
    "Configurando *Data Augmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AswKgudxtMLK"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='constant',\n",
    "    cval=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hk5zEh6tfLq"
   },
   "source": [
    "Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSFU34_l_4hb"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    datagen.flow(train_images_aug, train_labels, batch_size=32),\n",
    "    epochs=15,\n",
    "    validation_data=(test_images_aug, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzdkQ3j1V9-l"
   },
   "source": [
    "Salvando metadados do histórico de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHaunZaFWH8P"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "hist_df['epoch'] = hist_df.index + 1\n",
    "\n",
    "path_csv = os.path.join(BASE_OUTPUTS, 'training_log.csv')\n",
    "\n",
    "hist_df.to_csv(path_csv, index=False)\n",
    "\n",
    "print(f\"Log de treinamento salvo em: {path_csv}\")\n",
    "\n",
    "print(\"\\nPrévia dos dados salvos:\")\n",
    "print(hist_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiQ2EztFM8La"
   },
   "source": [
    "Gráficos do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3MEWlzHNEJi"
   },
   "outputs": [],
   "source": [
    "path_csv = os.path.join(BASE_OUTPUTS, 'training_log.csv')\n",
    "path_acc_graph = os.path.join(BASE_OUTPUTS, 'accuracy_plot.png')\n",
    "path_loss_graph = os.path.join(BASE_OUTPUTS, 'loss_plot.png')\n",
    "\n",
    "if not os.path.exists(path_csv):\n",
    "    print(f\"ERRO CRÍTICO: Arquivo de log não encontrado em {path_csv}\")\n",
    "else:\n",
    "    print(f\"Lendo histórico de: {path_csv}\")\n",
    "    df_log = pd.read_csv(path_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Whzzz2dzsy_B"
   },
   "source": [
    "Gráfico de Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLas6eZLNeeh"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df_log['epoch'], df_log['accuracy'], label='Treino', marker='o')\n",
    "plt.plot(df_log['epoch'], df_log['val_accuracy'], label='Validação', marker='o')\n",
    "\n",
    "plt.title('Evolução da Acurácia')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_acc_graph, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Gráfico de Acurácia salvo em: {path_acc_graph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OXHa5rGs3f1"
   },
   "source": [
    "Gráfico de Perda(*Loss*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Q4JZSqaOHXN"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df_log['epoch'], df_log['loss'], label='Treino', marker='o')\n",
    "plt.plot(df_log['epoch'], df_log['val_loss'], label='Validação', marker='o')\n",
    "\n",
    "plt.title('Evolução da Perda (Loss)')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_loss_graph, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Gráfico de Perda salvo em: {path_loss_graph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI2tP2j5AwZ0"
   },
   "source": [
    "**Etapa 5 - Avaliação de Desempenho**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22aVHHcr2L7y"
   },
   "source": [
    "Avaliando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWXUZzbiA2gX"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images_aug, test_labels, verbose=0)\n",
    "\n",
    "print(f\"Acurácia Final: {test_acc * 100:.2f}%\")\n",
    "print(f\"Perda Final: {test_loss:.4f}\")\n",
    "\n",
    "predictions = model.predict(test_images_aug)\n",
    "class_predictions = np.argmax(predictions, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTN9ESMctn5_"
   },
   "source": [
    "Salvando metadados do histórico de Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfv76OYktwq4"
   },
   "outputs": [],
   "source": [
    "globals_data = {\n",
    "    \"acuracia_teste\": test_acc,\n",
    "    \"perda_teste\": test_loss,\n",
    "    \"total_amostras\": len(test_images)\n",
    "}\n",
    "json_path = os.path.join(BASE_OUTPUTS, 'metrics.json')\n",
    "\n",
    "print(f\"Log salvo em: {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI9o_cIVu6DG"
   },
   "source": [
    "Gerando Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9OaiQo6u-V8"
   },
   "outputs": [],
   "source": [
    "with open(json_path, 'w') as f:\n",
    "    json.dump(globals_data, f, indent=4)\n",
    "\n",
    "txt_report = classification_report(test_labels, class_predictions, digits=4)\n",
    "path_txt = os.path.join(BASE_OUTPUTS, 'classification_report.txt')\n",
    "with open(path_txt, 'w') as f:\n",
    "    f.write(txt_report)\n",
    "\n",
    "matrix = confusion_matrix(test_labels, class_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusão - MNIST')\n",
    "plt.ylabel('Rótulo Real')\n",
    "plt.xlabel('Rótulo Predito')\n",
    "\n",
    "path_matrix = os.path.join(BASE_OUTPUTS, 'matrix_confusao.png')\n",
    "plt.savefig(path_matrix, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Dados do treinamento salvos em: {BASE_OUTPUTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWnWxCZS2QM5"
   },
   "source": [
    "Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdGyX4g51vva"
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(BASE_MODELS, 'mnist_model.keras')\n",
    "model.save(model_path)\n",
    "print(f\"Modelo salvo em: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLSqVzmVmnli"
   },
   "source": [
    "**Etapa 6 - Teste prático**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "26aeY5Kny1YK"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "BASE_MODELS = 'models'\n",
    "BASE_DATA = os.path.join('data')\n",
    "\n",
    "imagepath = os.path.join(BASE_DATA, 'numberimg.png')\n",
    "\n",
    "def predict_digit(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"ERRO: Imagem não encontrada em: {filepath}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Processando imagem: {filepath} ---\")\n",
    "\n",
    "    try:\n",
    "        img = image.load_img(filepath, target_size=(28, 28), color_mode=\"grayscale\")\n",
    "        img_array = image.img_to_array(img)\n",
    "\n",
    "        img_array = 255.0 - img_array\n",
    "\n",
    "        img_array /= 255.0\n",
    "\n",
    "        img_reshaped = img_array.reshape((1, 28, 28, 1))\n",
    "\n",
    "        predicoes = model.predict(img_reshaped)\n",
    "        predict_class = np.argmax(predicoes)\n",
    "        predict_confidence = np.max(predicoes) * 100\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "        plt.title(f\"Eu vejo o número: {predict_class}\\nCerteza: {predict_confidence:.2f}%\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        return predict_class\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao processar a imagem: {e}\")\n",
    "\n",
    "predict_digit(imagepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0Mk_tx8s-Nk"
   },
   "source": [
    "---\n",
    "## 7. Conclusão e Considerações Finais\n",
    "\n",
    "O desenvolvimento deste projeto permitiu demonstrar a eficácia do *framework* **Keras** na implementação ágil de redes neurais profundas. Através da construção de uma arquitetura *Multilayer Perceptron* (MLP), foi possível atingir uma acurácia competitiva no dataset MNIST.\n",
    "\n",
    "**Principais Resultados Alcançados:**\n",
    "* **Robustez:** A aplicação de *Data Augmentation* mitigou o *overfitting*, permitindo que o modelo generalizasse bem para dados de teste (Acurácia > 97%) e mantivesse a consistência entre as curvas de treino e validação.\n",
    "* **Aplicabilidade Prática:** O teste de inferência com imagens externas comprovou que o modelo não apenas memorizou o *dataset*, mas aprendeu a identificar padrões estruturais dos dígitos, funcionando corretamente com *inputs* do mundo real.\n",
    "* **Análise de Erros:** A Matriz de Confusão permitiu identificar que as maiores dificuldades do modelo residem em ambiguidades topológicas, fornecendo um caminho claro para melhorias futuras.\n",
    "\n",
    "**Trabalhos Futuros:**\n",
    "Visando a evolução deste protótipo acadêmico para um produto de *software* utilizável (*User-Friendly*), propõe-se:\n",
    "\n",
    "1.  **Desenvolvimento de Interface Web Interativa (Web App):**\n",
    "    A implementação de uma interface utilizando *frameworks* como **Streamlit** ou **Gradio**. Tais ferramentas permitem a integração de um *Canvas* digital (painel de desenho), onde o usuário pode desenhar o dígito diretamente no navegador com o mouse ou dedo, eliminando a necessidade de *softwares* externos (como Paint) e *upload* de arquivos.\n",
    "\n",
    "2.  **Implementação de Arquitetura CNN:**\n",
    "    Substituir a atual rede MLP por **Redes Neurais Convolucionais (CNNs)**. Esta arquitetura preserva a estrutura espacial 2D da imagem, sendo o estado da arte para visão computacional, o que elevaria a acurácia para níveis superiores a 99% e reduziria erros de confusão geométrica.\n",
    "\n",
    "3.  **Disponibilização via API (Microserviço):**\n",
    "    O encapsulamento do modelo treinado em uma **API REST** (utilizando FastAPI ou Flask). Isso permitiria que o modelo fosse consumido por aplicações externas, como aplicativos móveis (Android/iOS), permitindo o reconhecimento de dígitos a partir da câmera do celular em tempo real.\n",
    "\n",
    "**Entregáveis:**\n",
    "Todos os artefatos gerados (modelo treinado `.keras`, gráficos de desempenho e logs) encontram-se salvos e organizados nos diretórios `models/` e `outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTiFpHiCdtZb"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "print(\"--- Empacotando resultados para download ---\")\n",
    "\n",
    "shutil.make_archive('resultados_tcc', 'zip', BASE_OUTPUTS)\n",
    "\n",
    "shutil.make_archive('modelo_tcc', 'zip', BASE_MODELS)\n",
    "\n",
    "print(\"Arquivos zipados com sucesso!\")\n",
    "print(\"Iniciando download...\")\n",
    "\n",
    "files.download('resultados_tcc.zip')\n",
    "files.download('modelo_tcc.zip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ambiente_teste",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
